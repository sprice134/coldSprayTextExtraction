{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No articles found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# API key and Custom Search Engine ID\n",
    "API_KEY =  'AIzaSyDusmNWgEW1yG1X-l6y2GvAR7td2auhPRQ' # Replace with your API Key\n",
    "CX = \"97ebab36c362440cb\"     # Replace with your Custom Search Engine ID\n",
    "\n",
    "\n",
    "\n",
    "# query = ('\"cold spray\" \"Al 6061\" \"yield strength\"')\n",
    "# query = '\"cold spray\" (6061 aluminum OR 6061 aluminium OR \"Al 6061\" OR \"AA 6061\") (yield strength OR YS OR modulus OR \"Young\\'s modulus\" OR \"elastic modulus\" OR hardness OR microhardness OR \"Vickers hardness\" OR ductility OR elongation OR \"percent elongation\" OR \"% elongation\")'\n",
    "query = 'cold spray'\n",
    "\n",
    "# Base URL for Google Custom Search JSON API\n",
    "URL = \"https://www.googleapis.com/customsearch/v1\"\n",
    "\n",
    "params = {\n",
    "    \"key\": API_KEY,\n",
    "    \"cx\": CX,\n",
    "    \"q\": query,\n",
    "    \"num\": 1,  # Fetch only 3 results\n",
    "    \"start\": 1  # Starting from the first result\n",
    "}\n",
    "\n",
    "# Function to perform a single search\n",
    "def search_articles():\n",
    "    results = []\n",
    "    try:\n",
    "        response = requests.get(URL, params=params)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if \"items\" in response_data:\n",
    "            for item in response_data[\"items\"]:\n",
    "                title = item.get(\"title\", \"No title\")\n",
    "                link = item.get(\"link\", \"No link\")\n",
    "                snippet = item.get(\"snippet\", \"No description\")\n",
    "                results.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Link\": link,\n",
    "                    \"Snippet\": snippet\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Perform the search\n",
    "articles = search_articles()\n",
    "\n",
    "# Print the results\n",
    "if articles:\n",
    "    for idx, article in enumerate(articles, start=1):\n",
    "        print(f\"{idx}. Title: {article['Title']}\")\n",
    "        print(f\"   Link: {article['Link']}\")\n",
    "        print(f\"   Description: {article['Snippet']}\\n\")\n",
    "else:\n",
    "    print(\"No articles found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles saved to articles.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "if articles:\n",
    "    # Open a CSV file in write mode. \n",
    "    # You may adjust the file name or path as needed.\n",
    "    with open('articles.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writerow([\"Index\", \"Title\", \"Link\", \"Description\"])\n",
    "        \n",
    "        # Iterate through the articles and write each one to the CSV\n",
    "        for idx, article in enumerate(articles, start=1):\n",
    "            writer.writerow([idx, article['Title'], article['Link'], article['Snippet']])\n",
    "            \n",
    "    print(\"Articles saved to articles.csv\")\n",
    "else:\n",
    "    print(\"No articles found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: 404 Client Error: Not Found for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyDusmNWgEW1yG1X-l6y2GvAR7td2auhPRQ&cx=97ebab36c362440cb&q=%22cold+spray%22+%286061+aluminum+OR+6061+aluminium+OR+%22Al+6061%22+OR+%22AA+6061%22%29+%28yield+strength+OR+YS+OR+modulus+OR+%22Young%27s+modulus%22+OR+%22elastic+modulus%22+OR+hardness+OR+microhardness+OR+%22Vickers+hardness%22+OR+ductility+OR+elongation+OR+%22percent+elongation%22+OR+%22%25+elongation%22%29&num=10&start=1\n",
      "No articles found.\n",
      "Results saved to articles.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# API key and Custom Search Engine ID\n",
    "API_KEY =  'AIzaSyDusmNWgEW1yG1X-l6y2GvAR7td2auhPRQ' # Replace with your API Key\n",
    "CX = \"97ebab36c362440cb\"     # Replace with your Custom Search Engine ID\n",
    "\n",
    "\n",
    "# List of queries to perform multiple searches\n",
    "queries = [\n",
    "    '\"cold spray\" (6061 aluminum OR 6061 aluminium OR \"Al 6061\" OR \"AA 6061\") (yield strength OR YS OR modulus OR \"Young\\'s modulus\" OR \"elastic modulus\" OR hardness OR microhardness OR \"Vickers hardness\" OR ductility OR elongation OR \"percent elongation\" OR \"% elongation\")',\n",
    "    '\"cold spray\" \"Al 6061\" \"yield strength\"',\n",
    "    # Add more queries here if needed\n",
    "]\n",
    "\n",
    "# Base URL for Google Custom Search JSON API\n",
    "URL = \"https://www.googleapis.com/customsearch/v1\"\n",
    "\n",
    "# Parameters for the search\n",
    "num_results_per_page = 10\n",
    "start = 1\n",
    "\n",
    "all_articles = []\n",
    "max_pages = 10  # For safety, limit to 10 pages. You can adjust this as needed.\n",
    "page_count = 0\n",
    "\n",
    "while True:\n",
    "    # Construct params for the current page\n",
    "    params = {\n",
    "        \"key\": API_KEY,\n",
    "        \"cx\": CX,\n",
    "        \"q\": query,\n",
    "        \"num\": num_results_per_page,\n",
    "        \"start\": start\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(URL, params=params)\n",
    "        response.raise_for_status()  # Raise an HTTPError on bad response\n",
    "        response_data = response.json()\n",
    "\n",
    "        items = response_data.get(\"items\", [])\n",
    "        if not items:\n",
    "            # No more results\n",
    "            break\n",
    "\n",
    "        # Extract articles and add them to the list\n",
    "        for item in items:\n",
    "            title = item.get(\"title\", \"No title\")\n",
    "            link = item.get(\"link\", \"No link\")\n",
    "            snippet = item.get(\"snippet\", \"No description\")\n",
    "            all_articles.append({\n",
    "                \"Title\": title,\n",
    "                \"Link\": link,\n",
    "                \"Snippet\": snippet\n",
    "            })\n",
    "\n",
    "        # Prepare next page\n",
    "        page_count += 1\n",
    "        start += num_results_per_page\n",
    "\n",
    "        # If we reached our max_pages limit, stop\n",
    "        if page_count >= max_pages:\n",
    "            break\n",
    "\n",
    "        # (Optional) Sleep to avoid hitting rate limits too quickly\n",
    "        time.sleep(5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        # Break out of the loop and return what we have so far\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "if all_articles:\n",
    "    for idx, article in enumerate(all_articles, start=1):\n",
    "        print(f\"{idx}. Title: {article['Title']}\")\n",
    "        print(f\"   Link: {article['Link']}\")\n",
    "        print(f\"   Description: {article['Snippet']}\\n\")\n",
    "else:\n",
    "    print(\"No articles found.\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = \"articles.csv\"\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Index\", \"Title\", \"Link\", \"Description\"])\n",
    "    for idx, article in enumerate(all_articles, start=1):\n",
    "        writer.writerow([idx, article['Title'], article['Link'], article['Snippet']])\n",
    "\n",
    "print(f\"Results saved to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfSearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
