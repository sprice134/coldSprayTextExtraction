{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_crossref_metadata(title):\n",
    "    url = \"https://api.crossref.org/works\"\n",
    "    params = {\n",
    "        \"query.bibliographic\": title,\n",
    "        \"rows\": 1  # return the top result\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        items = data.get(\"message\", {}).get(\"items\", [])\n",
    "        if items:\n",
    "            return items[0]\n",
    "    return None\n",
    "\n",
    "def reduce_metadata(metadata):\n",
    "    # Extract the title from the 'title' list (if available)\n",
    "    title_list = metadata.get(\"title\", [])\n",
    "    title = title_list[0] if title_list else \"NA\"\n",
    "    \n",
    "    # Extract abstract (if available)\n",
    "    abstract = metadata.get(\"abstract\", \"NA\")\n",
    "    \n",
    "    # Extract date published from the 'issued' field\n",
    "    issued = metadata.get(\"issued\", {})\n",
    "    date_parts = issued.get(\"date-parts\", [])\n",
    "    if date_parts and len(date_parts[0]) > 0:\n",
    "        date_published = \"-\".join(str(part) for part in date_parts[0])\n",
    "    else:\n",
    "        date_published = \"NA\"\n",
    "        \n",
    "    # Extract DOI\n",
    "    doi = metadata.get(\"DOI\", \"NA\")\n",
    "    ref_count = metadata.get(\"reference-count\", \"NA\")\n",
    "    citations = metadata.get(\"is-referenced-by-count\", \"NA\")\n",
    "    container_title = metadata.get(\"container-title\", [])\n",
    "    journal = container_title[0] if container_title else \"NA\"\n",
    "    date_updated = metadata.get(\"indexed\", {}).get(\"date-time\", \"NA\")\n",
    "    \n",
    "    return {\n",
    "        \"Title\": title,\n",
    "        \"Abstract\": abstract,\n",
    "        \"Date Published\": date_published,\n",
    "        \"DOI\": doi,\n",
    "        \"Number of References\": ref_count,\n",
    "        \"Number of Citations\": citations,\n",
    "        \"Journal\": journal,\n",
    "        \"Date Updated (of metadata)\": date_updated\n",
    "    }\n",
    "\n",
    "def text_similarity(text1, text2):\n",
    "    return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()\n",
    "\n",
    "json_file = 'articlesMetaData.json'\n",
    "if os.path.exists(json_file):\n",
    "    print('Skipping Creation: File Already Exists')\n",
    "else:\n",
    "    df = pd.read_excel('documents/articles.xlsx', sheet_name='6061 Al')\n",
    "\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        article = {\n",
    "            \"filename\": f\"Article_{row['Index']}.pdf\",\n",
    "            \"title\": \"\" if pd.isna(row['Title']) else row['Title'],\n",
    "            \"link\": \"\" if pd.isna(row['Link']) else row['Link'],\n",
    "            \"extractedText\": \"\"\n",
    "        }\n",
    "        data.append(article)\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed articles saved to articlesMetaDataCrossRef.json\n"
     ]
    }
   ],
   "source": [
    "input_json_path = \"articlesMetaData.json\"\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r', encoding='utf-8') as infile:\n",
    "    articles = json.load(infile)\n",
    "\n",
    "# Process each article: get metadata from Crossref and add a new \"metadata\" field\n",
    "for article in articles:\n",
    "    article_title = article.get(\"title\", \"\")\n",
    "    if article_title:\n",
    "        crossref_metadata = get_crossref_metadata(article_title)\n",
    "        if crossref_metadata:\n",
    "            reduced = reduce_metadata(crossref_metadata)\n",
    "            returned_title = reduced.get(\"Title\", \"NA\")\n",
    "            similarity = text_similarity(article_title, returned_title)\n",
    "            if similarity < 0.9:\n",
    "                article[\"metadata\"] = \"No metadata found\"\n",
    "            else:\n",
    "                article[\"metadata\"] = reduced\n",
    "        else:\n",
    "            article[\"metadata\"] = \"No metadata found\"\n",
    "    else:\n",
    "        article[\"metadata\"] = \"No title provided\"\n",
    "\n",
    "# Save the new JSON to a file (you can change the output path as needed)\n",
    "output_json_path = \"articlesMetaDataCrossRef.json\"\n",
    "with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(articles, outfile, indent=4)\n",
    "\n",
    "print(f\"Processed articles saved to {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfSearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
